image:
  registry: us-east1-docker.pkg.dev
  repository: rick-vertex-ai/gke-llm/deepspeed-mii
  tag: latest
client:
  enabled: true
  ## @param client.useJob Deploy as job
  ##
  useJob: false
  ## @param client.backoffLimit set backoff limit of the job
  ##
  ## @param client.command Override default container command (useful when using custom images)
  ##
  extraEnvVars: 
     - name: sshm-size
       value: 1g

  command: []
  ## @param client.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param client.terminationGracePeriodSeconds Client termination grace period (in seconds)
  ##
  resources:
    limits: 
       nvidia.com/gpu: 1
    requests: {}
  livenessProbe:
    enabled: false
  readinessProbe:
    enabled: false
  containerSecurityContext:
    enabled: false
  nodeSelector: 
      cloud.google.com/gke-accelerator: nvidia-tesla-t4
worker:
  ## @param worker.enabled Enable Worker deployment
  ##
  enabled: true
  ## @param worker.slotsPerNode Number of slots available per worker node
  ##
  slotsPerNode: 1
  ## @param worker.extraEnvVars Array with extra environment variables to add to client nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars:  
    - name: sshm-size
      value: 1g
  ## @param worker.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param worker.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param worker.replicaCount Number of Worker replicas to deploy
  ##
  replicaCount: 2
  resources:
    limits: 
      nvidia.com/gpu: 1
  nodeSelector: 
      cloud.google.com/gke-accelerator: nvidia-tesla-t4